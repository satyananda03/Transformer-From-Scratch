{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c8f9f321c3664aebad7c65f2422d7fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6969a4801fff45b38b3d4f39169549d0",
              "IPY_MODEL_4456b0f7740f4ca0a46c1aeb85a46606",
              "IPY_MODEL_03064a73400c4c8d85d4efb7f0243835"
            ],
            "layout": "IPY_MODEL_39db774dca7244438c4b643f45036759"
          }
        },
        "6969a4801fff45b38b3d4f39169549d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78aa935f1423495c85ca6732935534ad",
            "placeholder": "​",
            "style": "IPY_MODEL_1e4e568caab54a9785204514ea03db02",
            "value": "Epoch 29: 100%"
          }
        },
        "4456b0f7740f4ca0a46c1aeb85a46606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33c71f60c5d74092aed280ec60ad6712",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f28f6d5409a41158423483be5a51a77",
            "value": 5
          }
        },
        "03064a73400c4c8d85d4efb7f0243835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66a3e96f05cb4211b11ed880e3616ae1",
            "placeholder": "​",
            "style": "IPY_MODEL_b309652ab1a4460f82dc6a0091eddd3b",
            "value": " 5/5 [00:00&lt;00:00, 53.26it/s, v_num=44, train_loss=0.0276]"
          }
        },
        "39db774dca7244438c4b643f45036759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "78aa935f1423495c85ca6732935534ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e4e568caab54a9785204514ea03db02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33c71f60c5d74092aed280ec60ad6712": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f28f6d5409a41158423483be5a51a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66a3e96f05cb4211b11ed880e3616ae1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b309652ab1a4460f82dc6a0091eddd3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d31fbfa7470a4f26ac8d419d2979bead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04c0fbc9c20f4fa8b7d958aad4f7103d",
              "IPY_MODEL_84a1755a1b6b421aaaa1d0451df39241",
              "IPY_MODEL_aa8ba5cbf5504a5c9cb1d12343dc5800"
            ],
            "layout": "IPY_MODEL_e631567250f5412ea121ad4429cbc7cc"
          }
        },
        "04c0fbc9c20f4fa8b7d958aad4f7103d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c80c32c08ff34dfc971d59876992a6d1",
            "placeholder": "​",
            "style": "IPY_MODEL_c4cb6a144aaf45ab8db48c8f40102728",
            "value": "Epoch 49: 100%"
          }
        },
        "84a1755a1b6b421aaaa1d0451df39241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9075d1fab03f4a4b87ff430d6bc157dc",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a72dae748247471a9962b15ba90210bf",
            "value": 2
          }
        },
        "aa8ba5cbf5504a5c9cb1d12343dc5800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca627299fd4547f391053858e3edc55c",
            "placeholder": "​",
            "style": "IPY_MODEL_c8e638b7b75d44af96c353453187930e",
            "value": " 2/2 [00:00&lt;00:00, 40.96it/s, v_num=33, train_loss=0.0129]"
          }
        },
        "e631567250f5412ea121ad4429cbc7cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "c80c32c08ff34dfc971d59876992a6d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4cb6a144aaf45ab8db48c8f40102728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9075d1fab03f4a4b87ff430d6bc157dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a72dae748247471a9962b15ba90210bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca627299fd4547f391053858e3edc55c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8e638b7b75d44af96c353453187930e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRiPsOin4Ned",
        "outputId": "0d633562-c0ab-4945-9350-89bb2fdcdefd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.5.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.0)\n",
            "Collecting torchmetrics>0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-1.8.1-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (25.0)\n",
            "Requirement already satisfied: typing-extensions>4.5.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.14.1)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.12.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics>0.7.0->pytorch-lightning) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n",
            "Downloading pytorch_lightning-2.5.3-py3-none-any.whl (828 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m828.2/828.2 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.8.1-py3-none-any.whl (982 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.0/983.0 kB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed lightning-utilities-0.15.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 pytorch-lightning-2.5.3 torchmetrics-1.8.1\n"
          ]
        }
      ],
      "source": [
        "%pip install -U pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch ## torch let's us create tensors and also provides helper functions\n",
        "import torch.nn as nn ## torch.nn gives us nn.Module, nn.Embedding() and nn.Linear()\n",
        "import torch.nn.functional as F # This gives us the softmax() and argmax()\n",
        "from torch.optim import Adam # This is the optimizer we will use\n",
        "import lightning as L # Lightning makes it easier to write, optimize and scale our code\"\n",
        "from torch.utils.data import TensorDataset, DataLoader # We'll store our data in DataLoaders"
      ],
      "metadata": {
        "id": "ACqLIc8l4kUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Input & Output Data"
      ],
      "metadata": {
        "id": "dXIajeac4ZGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kamus dan Data Anda\n",
        "input_vocab_id = {'<SOS>': 0, '<EOS>': 1, '<PAD>': 2, 'saya': 3, 'kamu': 4, 'dia': 5, 'makan': 6, 'minum': 7, 'air': 8, 'nasi': 9, 'ikan': 10, 'suka': 11, 'ini': 12, 'itu': 13, 'pergi': 14, 'sekolah': 15, 'rumah': 16, 'ke':17}\n",
        "output_vocab_en = {'<SOS>': 0, '<EOS>': 1, '<PAD>': 2, 'I': 3, 'you': 4, 'he': 5, 'she': 6, 'eat': 7, 'drink': 8, 'water': 9, 'rice': 10, 'fish': 11, 'like': 12, 'this': 13, 'that': 14, 'go': 15, 'to': 16, 'school': 17, 'home': 18}\n",
        "PAD_IDX = output_vocab_en['<PAD>']\n",
        "MAX_LEN_INPUT = 5\n",
        "MAX_LEN_OUTPUT = 6\n",
        "\n",
        "def tokenize_and_pad(sentence, vocab, max_len, is_input=True):\n",
        "    tokens = [vocab[word] for word in sentence.split()]\n",
        "    if is_input:\n",
        "        tokens = tokens + [vocab['<EOS>']]\n",
        "    padded_tokens = tokens + [vocab['<PAD>']] * (max_len - len(tokens))\n",
        "    return padded_tokens\n",
        "\n",
        "indonesian_sentences = ['saya suka nasi', 'kamu makan ikan', 'dia minum air', 'saya pergi ke sekolah', 'kamu pergi ke rumah', 'dia makan itu', 'saya suka ini', 'kamu suka ikan', 'dia pergi', 'saya makan']\n",
        "english_translations = ['I like rice', 'you eat fish', 'she drink water', 'I go to school', 'you go to home', 'she eat that', 'I like this', 'you like fish', 'she go', 'I eat']\n",
        "\n",
        "inputs_list, decoder_inputs_list, labels_list = [], [], []\n",
        "for i in range(len(indonesian_sentences)):\n",
        "    input_tokens = tokenize_and_pad(indonesian_sentences[i], input_vocab_id, MAX_LEN_INPUT, is_input=True)\n",
        "    inputs_list.append(input_tokens)\n",
        "    decoder_in = tokenize_and_pad(english_translations[i], output_vocab_en, MAX_LEN_OUTPUT - 1, is_input=False)\n",
        "    decoder_in = [output_vocab_en['<SOS>']] + decoder_in\n",
        "    decoder_inputs_list.append(decoder_in)\n",
        "    label_out = tokenize_and_pad(english_translations[i], output_vocab_en, MAX_LEN_OUTPUT - 1, is_input=False)\n",
        "    label_out = label_out + [output_vocab_en['<EOS>']]\n",
        "    labels_list.append(label_out)\n",
        "\n",
        "inputs_tensor = torch.tensor(inputs_list)\n",
        "decoder_inputs_tensor = torch.tensor(decoder_inputs_list)\n",
        "labels_tensor = torch.tensor(labels_list)\n",
        "\n",
        "dataset = TensorDataset(inputs_tensor, decoder_inputs_tensor, labels_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=2)"
      ],
      "metadata": {
        "id": "VxGSs69n9Eaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Positional Encoding"
      ],
      "metadata": {
        "id": "ZATPkhR543AD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len): # Hapus nilai default 2 dan 3\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(start=0, end=max_len, step=1).float().unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Tambahkan dimensi batch ke positional encoding\n",
        "        return x + self.pe[:x.size(1), :].unsqueeze(0)"
      ],
      "metadata": {
        "id": "wro6CcO69J26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-head Attention"
      ],
      "metadata": {
        "id": "lQX1_eAb9eEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, d_model, row_dim=0, col_dim=1): # Hapus nilai default 2\n",
        "        super().__init__()\n",
        "        self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "        self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "        self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "        self.row_dim = row_dim\n",
        "        self.col_dim = col_dim\n",
        "\n",
        "    def forward(self, encodings_q, encodings_k, encodings_v, mask=None):\n",
        "        ## We pass those sets of encodings to the various weight matrices.\n",
        "        q = self.W_q(encodings_q)\n",
        "        k = self.W_k(encodings_k)\n",
        "        v = self.W_v(encodings_v)\n",
        "        sims = torch.matmul(q, k.transpose(dim0=self.row_dim, dim1=self.col_dim))\n",
        "        scaled_sims = sims / torch.tensor(k.size(self.col_dim)**0.5)\n",
        "        if mask is not None:\n",
        "            scaled_sims = scaled_sims.masked_fill(mask=mask, value=-1e9)\n",
        "        attention_percents = F.softmax(scaled_sims, dim=self.col_dim)\n",
        "        attention_scores = torch.matmul(attention_percents, v)\n",
        "        # print(q.shape, k.shape, sims.shape)\n",
        "        return attention_scores\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, row_dim=1, col_dim=2, num_heads=1): # Hapus nilai default 2\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([\n",
        "            Attention(d_model, row_dim, col_dim) for _ in range(num_heads)\n",
        "        ])\n",
        "        self.reduce_attention_dim = nn.Linear(in_features=(num_heads * d_model), out_features=d_model)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        # FIX: Gabungkan pada dimensi fitur (dim=-1)\n",
        "        multihead_scores = torch.cat([head(encodings_q=q, encodings_k=k, encodings_v=v, mask=mask) for head in self.heads], dim=-1)\n",
        "        return self.reduce_attention_dim(multihead_scores)"
      ],
      "metadata": {
        "id": "Doq6xTFf9STE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feed Forwad Network"
      ],
      "metadata": {
        "id": "BxXxclg87vj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout, activation=nn.ReLU):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.act = activation()\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.fc2(x)\n",
        "        return x  # shape (B, L, d_model)"
      ],
      "metadata": {
        "id": "enzORNw79cqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "AqgYEp-D8Gxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, d_model, num_heads=1, d_ff=8, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.mha = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.ffn = FeedForward(d_model=d_model, d_ff=d_ff, dropout=dropout, activation=nn.ReLU)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "    def forward(self, x):\n",
        "        # x: (B, L, d_model)\n",
        "        mha_out = self.mha(x, x, x,  mask = None)\n",
        "        # 1st residual + norm (post-ln)\n",
        "        x = self.norm1(x + mha_out)\n",
        "        # feed-forward\n",
        "        ff = self.ffn(x)\n",
        "        # 2nd residual + norm\n",
        "        x = self.norm2(x + ff)\n",
        "        return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, num_tokens, d_model, max_len, n_blocks=1, num_heads=1):\n",
        "        super().__init__()\n",
        "        self.we = nn.Embedding(num_embeddings=num_tokens, embedding_dim=d_model)\n",
        "        self.pe = PositionEncoding(d_model=d_model, max_len=max_len)\n",
        "        self.encoder_blocks = nn.ModuleList([\n",
        "            EncoderBlock(d_model=d_model, num_heads=num_heads, d_ff=8)\n",
        "            for _ in range(n_blocks)\n",
        "        ])\n",
        "\n",
        "    def forward(self, token_ids):\n",
        "        word_embeddings = self.we(token_ids)\n",
        "        x = self.pe(word_embeddings) # Gunakan 'x' sebagai variabel iteratif\n",
        "        for block in self.encoder_blocks:\n",
        "            x = block(x) # Gunakan output block sebelumnya sebagai input block selanjutnya\n",
        "        return x"
      ],
      "metadata": {
        "id": "yQYBqahL9vW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ],
      "metadata": {
        "id": "KDLKIFbRPttY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, d_model, num_heads=1, d_ff=8, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.mha1 = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.mha2 = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.ffn = FeedForward(d_model=d_model, d_ff=d_ff, dropout=dropout, activation=nn.ReLU)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, encoder_out, mask):\n",
        "      mha1_out = self.mha1(q = x, k = x, v = x, mask = mask)\n",
        "      x = self.norm1(x + mha1_out)\n",
        "      mha2_out = self.mha2(q = x, k = encoder_out, v = encoder_out, mask = None)\n",
        "      x = self.norm2(x + mha2_out)\n",
        "      ff = self.ffn(x)\n",
        "      x = self.norm3(x + ff)\n",
        "      return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, num_tokens, d_model, max_len, n_blocks=1, num_heads=1):\n",
        "        super().__init__()\n",
        "        self.we = nn.Embedding(num_embeddings=num_tokens, embedding_dim=d_model)\n",
        "        self.pe = PositionEncoding(d_model=d_model, max_len=max_len)\n",
        "        self.decoder_blocks = nn.ModuleList([\n",
        "            DecoderBlock(d_model=d_model, num_heads=num_heads, d_ff=8)\n",
        "            for _ in range(n_blocks)\n",
        "        ])\n",
        "        self.fc_layer = nn.Linear(in_features=d_model, out_features=num_tokens)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def forward(self, token_ids, encoder_out):\n",
        "        seq_len = token_ids.size(1)\n",
        "        word_embeddings = self.we(token_ids)\n",
        "        x = self.pe(word_embeddings)\n",
        "        mask = torch.tril(torch.ones(seq_len, seq_len)).to(self.device)\n",
        "        mask = mask == 0\n",
        "        for block in self.decoder_blocks:\n",
        "            x = block(x, encoder_out, mask)\n",
        "        fc_layer_output = self.fc_layer(x)\n",
        "        return fc_layer_output"
      ],
      "metadata": {
        "id": "05GJUI6T90ZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer"
      ],
      "metadata": {
        "id": "ReJFxyKPRUky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(L.LightningModule):\n",
        "    # Perbarui __init__ untuk menerima semua parameter\n",
        "    def __init__(self, input_vocab_size, output_vocab_size, d_model, max_len_input, max_len_output):\n",
        "        super().__init__()\n",
        "        # Teruskan parameter dengan benar ke Encoder dan Decoder\n",
        "        self.encoder = Encoder(num_tokens=input_vocab_size, d_model=d_model, max_len=max_len_input)\n",
        "        self.decoder = Decoder(num_tokens=output_vocab_size, d_model=d_model, max_len=max_len_output)\n",
        "        self.loss = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "        self.output_vocab = output_vocab_en\n",
        "        self.max_len_input = max_len_input\n",
        "        self.max_len_output = max_len_output\n",
        "\n",
        "    def forward(self, inputs, labels):\n",
        "        encoder_values = self.encoder(inputs)\n",
        "        output_presoftmax = self.decoder(labels, encoder_values) # Input ke decoder dengan teacher forcing (Single Pass) tanpa auto regressive\n",
        "        return output_presoftmax\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return Adam(self.parameters(), lr=0.005)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        encoder_input, decoder_input_teacher_forcing, decoder_target = batch\n",
        "        output = self.forward(encoder_input, decoder_input_teacher_forcing)\n",
        "        loss = self.loss(output.reshape(-1, output.size(-1)), decoder_target.reshape(-1))\n",
        "        self.log('train_loss', loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def predict(self, input_sentence_tensor, max_output_len=5): # Inference dengan auto regressive di decoder\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            if input_sentence_tensor.dim() == 1:\n",
        "                input_sentence_tensor = input_sentence_tensor.unsqueeze(0)\n",
        "\n",
        "            encoder_output = self.encoder(input_sentence_tensor.to(self.device))\n",
        "            decoder_input = torch.tensor([[self.output_vocab['<SOS>']]]).to(self.device)\n",
        "            predicted_tokens = []\n",
        "\n",
        "            for _ in range(max_output_len):\n",
        "                output_logits = self.decoder(decoder_input, encoder_output)\n",
        "                last_token_logits = output_logits[:, -1, :]\n",
        "                predicted_token_id = torch.argmax(last_token_logits, dim=-1)\n",
        "\n",
        "                if predicted_token_id.item() == self.output_vocab['<EOS>']:\n",
        "                    break\n",
        "\n",
        "                predicted_tokens.append(predicted_token_id.item())\n",
        "                decoder_input = torch.cat([decoder_input, predicted_token_id.unsqueeze(0)], dim=1)\n",
        "\n",
        "            id_to_word = {v: k for k, v in self.output_vocab.items()}\n",
        "            predicted_sentence = [id_to_word[token_id] for token_id in predicted_tokens]\n",
        "            return predicted_sentence"
      ],
      "metadata": {
        "id": "gz2sSPFc95iO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "z4TT8dC5-DA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisialisasi dan pelatihan model\n",
        "MAX_LEN_INPUT = 5\n",
        "MAX_LEN_OUTPUT = 6\n",
        "\n",
        "# Panggil kelas Transformer dengan urutan argumen yang benar\n",
        "transformer = Transformer(\n",
        "    input_vocab_size=len(input_vocab_id),\n",
        "    output_vocab_size=len(output_vocab_en),\n",
        "    d_model=16,\n",
        "    max_len_input=MAX_LEN_INPUT,\n",
        "    max_len_output=MAX_LEN_OUTPUT\n",
        ")\n",
        "\n",
        "trainer = L.Trainer(max_epochs=30, enable_progress_bar=True)\n",
        "trainer.fit(transformer, train_dataloaders=dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694,
          "referenced_widgets": [
            "c8f9f321c3664aebad7c65f2422d7fe4",
            "6969a4801fff45b38b3d4f39169549d0",
            "4456b0f7740f4ca0a46c1aeb85a46606",
            "03064a73400c4c8d85d4efb7f0243835",
            "39db774dca7244438c4b643f45036759",
            "78aa935f1423495c85ca6732935534ad",
            "1e4e568caab54a9785204514ea03db02",
            "33c71f60c5d74092aed280ec60ad6712",
            "4f28f6d5409a41158423483be5a51a77",
            "66a3e96f05cb4211b11ed880e3616ae1",
            "b309652ab1a4460f82dc6a0091eddd3b"
          ]
        },
        "id": "UX3sQYG8-EVg",
        "outputId": "1d93bff6-62ea-479e-e62c-c5d2290ddaea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: 💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: \n",
            "  | Name    | Type             | Params | Mode \n",
            "-----------------------------------------------------\n",
            "0 | encoder | Encoder          | 1.7 K  | train\n",
            "1 | decoder | Decoder          | 3.1 K  | train\n",
            "2 | loss    | CrossEntropyLoss | 0      | train\n",
            "-----------------------------------------------------\n",
            "4.8 K     Trainable params\n",
            "0         Non-trainable params\n",
            "4.8 K     Total params\n",
            "0.019     Total estimated model params size (MB)\n",
            "46        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name    | Type             | Params | Mode \n",
            "-----------------------------------------------------\n",
            "0 | encoder | Encoder          | 1.7 K  | train\n",
            "1 | decoder | Decoder          | 3.1 K  | train\n",
            "2 | loss    | CrossEntropyLoss | 0      | train\n",
            "-----------------------------------------------------\n",
            "4.8 K     Trainable params\n",
            "0         Non-trainable params\n",
            "4.8 K     Total params\n",
            "0.019     Total estimated model params size (MB)\n",
            "46        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8f9f321c3664aebad7c65f2422d7fe4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: `Trainer.fit` stopped: `max_epochs=30` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=30` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "oR1kBFzl96dP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh penggunaan inferensi\n",
        "input_sentence = \"kamu makan ikan\"\n",
        "input_tokens = [input_vocab_id[word] for word in input_sentence.split()]\n",
        "input_tensor = torch.tensor(input_tokens)\n",
        "\n",
        "print(f\"Menerjemahkan: '{input_sentence}' -> {input_tensor}\")\n",
        "predicted_translation = transformer.predict(input_tensor)\n",
        "print(f\"Hasil prediksi: {predicted_translation}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7hoAXcH-At5",
        "outputId": "00d66dbb-787b-4e1b-e5cb-80f7d2f7b4d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Menerjemahkan: 'kamu makan ikan' -> tensor([ 4,  6, 10])\n",
            "Hasil prediksi: ['you', 'eat', 'fish', 'fish', 'fish']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Transformer With Auto Regressive Inference"
      ],
      "metadata": {
        "id": "iNbjmdK18255"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## first, a dictionary for the input vocabulary\n",
        "input_vocab = {'<SOS>': 0, ## <SOS> = start of sequence.\n",
        "               'lets': 1,\n",
        "               'to': 2,\n",
        "               'go': 3}\n",
        "\n",
        "## Now a dictionary for the output vocabulary\n",
        "output_vocab = {'<SOS>': 0,\n",
        "                'ir': 1,\n",
        "                'vamos': 2,\n",
        "                'y': 3,\n",
        "                '<EOS>': 4,\n",
        "                '<PAD>': 5} # Tambahkan token padding\n",
        "\n",
        "# Tentukan PAD_IDX sesuai dengan ID token <PAD>\n",
        "PAD_IDX = output_vocab['<PAD>']\n",
        "\n",
        "# Output vocabulary: {'<SOS>': 0, 'ir': 1, 'vamos': 2, 'y': 3, '<EOS>': 4, '<PAD>': 5}\n",
        "# Input: \"lets go\" -> Output: \"vamos y\"\n",
        "# Input: \"to go\"   -> Output: \"ir\"\n",
        "inputs = torch.tensor([[1, 3],\n",
        "                       [2, 3]])\n",
        "\n",
        "# Panjang sekuens terpanjang adalah 3 (untuk 'vamos y')\n",
        "# Pad 'ir' agar panjangnya sama\n",
        "decoder_inputs = torch.tensor([[0, 2, 3],    # <SOS> 'vamos' 'y'\n",
        "                               [0, 1, PAD_IDX]]) # <SOS> 'ir' <PAD>\n",
        "\n",
        "labels = torch.tensor([[2, 3, 4],        # 'vamos' 'y' <EOS>\n",
        "                       [1, 4, PAD_IDX]]) # 'ir' <EOS> <PAD>\n",
        "\n",
        "dataset = TensorDataset(inputs, labels)\n",
        "dataloader = DataLoader(dataset)"
      ],
      "metadata": {
        "id": "IYuV7IclqjmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionEncoding(nn.Module):\n",
        "    def __init__(self, d_model=2, max_len=3):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(start=0, end=max_len, step=1).float().unsqueeze(1)\n",
        "        div_term = 1/torch.tensor(10000.0)**(torch.arange(start=0, end=d_model, step=2).float() / d_model)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term) ## every other column, starting with the 1st, has sin() values\n",
        "        pe[:, 1::2] = torch.cos(position * div_term) ## every other column, starting with the 2nd, has cos() values\n",
        "        ## Now we \"register 'pe'.\n",
        "        self.register_buffer('pe', pe)\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:x.size(0), :]\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, d_model=2, row_dim=0, col_dim=1):\n",
        "        super().__init__()\n",
        "        self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "        self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "        self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "        self.row_dim = row_dim\n",
        "        self.col_dim = col_dim\n",
        "\n",
        "    def forward(self, encodings_q, encodings_k, encodings_v, mask=None):\n",
        "        ## We pass those sets of encodings to the various weight matrices.\n",
        "        q = self.W_q(encodings_q)\n",
        "        k = self.W_k(encodings_k)\n",
        "        v = self.W_v(encodings_v)\n",
        "        sims = torch.matmul(q, k.transpose(dim0=self.row_dim, dim1=self.col_dim))\n",
        "        scaled_sims = sims / torch.tensor(k.size(self.col_dim)**0.5)\n",
        "        if mask is not None:\n",
        "            scaled_sims = scaled_sims.masked_fill(mask=mask, value=-1e9)\n",
        "        attention_percents = F.softmax(scaled_sims, dim=self.col_dim)\n",
        "        attention_scores = torch.matmul(attention_percents, v)\n",
        "        # print(q.shape, k.shape, sims.shape)\n",
        "        return attention_scores\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model=2, row_dim=1, col_dim=2, num_heads=1): # Sesuaikan row/col dim untuk (B, L, D)\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList(\n",
        "            [Attention(d_model, row_dim, col_dim)\n",
        "             for _ in range(num_heads)]\n",
        "        )\n",
        "        self.reduce_attention_dim = nn.Linear(in_features=(num_heads*d_model), out_features=d_model)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        # FIX: Gabungkan pada dimensi fitur (dim=-1)\n",
        "        multihead_scores = torch.cat([head(encodings_q=q, encodings_k=k, encodings_v=v, mask=mask) for head in self.heads], dim=-1)\n",
        "\n",
        "        # Sekarang multihead_scores punya shape (B, L, num_heads*d_model)\n",
        "        # yang cocok untuk reduce_attention_dim\n",
        "        return self.reduce_attention_dim(multihead_scores)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout, activation=nn.ReLU):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.act = activation()\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.fc2(x)\n",
        "        return x  # shape (B, L, d_model)\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, d_model=2, num_heads=1, d_ff=8, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.mha = MultiHeadAttention(d_model=d_model, num_heads=num_heads)  # (B,L,d_model)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.ffn = FeedForward(d_model=d_model, d_ff=d_ff, dropout=dropout, activation=nn.ReLU)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "    def forward(self, x):\n",
        "        # x: (B, L, d_model)\n",
        "        mha_out = self.mha(x, x, x,  mask = None)\n",
        "        # 1st residual + norm (post-ln)\n",
        "        x = self.norm1(x + mha_out)\n",
        "        # feed-forward\n",
        "        ff = self.ffn(x)\n",
        "        # 2nd residual + norm\n",
        "        x = self.norm2(x + ff)\n",
        "        return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, num_tokens=4, d_model=2, max_len=3, n_blocks=1, num_heads=1):\n",
        "        super().__init__()\n",
        "        # L.seed_everything(42)\n",
        "        # Embedding + Positional Encoding\n",
        "        self.we = nn.Embedding(num_embeddings=num_tokens, embedding_dim=d_model)\n",
        "        self.pe = PositionEncoding(d_model=d_model, max_len=max_len)\n",
        "        # Stacked Encoder Block\n",
        "        self.encoder_blocks = nn.ModuleList([\n",
        "            EncoderBlock(d_model=d_model, num_heads=num_heads, d_ff=8)\n",
        "            for block in range(n_blocks)\n",
        "        ])\n",
        "\n",
        "    def forward(self, token_ids):\n",
        "        word_embeddings = self.we(token_ids)\n",
        "        x = self.pe(word_embeddings) # Gunakan 'x' sebagai variabel iteratif\n",
        "        for block in self.encoder_blocks:\n",
        "            x = block(x) # Gunakan output block sebelumnya sebagai input block selanjutnya\n",
        "        return x\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self, d_model=2, num_heads=1, d_ff=8, dropout=0.0):\n",
        "    super().__init__()\n",
        "    self.mha1 = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
        "    self.norm1 = nn.LayerNorm(d_model)\n",
        "    self.mha2 = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
        "    self.norm2 = nn.LayerNorm(d_model)\n",
        "    self.ffn = FeedForward(d_model=d_model, d_ff=d_ff, dropout=dropout, activation=nn.ReLU)\n",
        "    self.norm3 = nn.LayerNorm(d_model)\n",
        "\n",
        "  def forward(self, x, encoder_out, mask):\n",
        "    mha1_out = self.mha1(q = x, k = x, v = x, mask = mask)\n",
        "    x = self.norm1(x + mha1_out)\n",
        "    mha2_out = self.mha2(q = x, k = encoder_out, v = encoder_out, mask = None)\n",
        "    x = self.norm2(x + mha2_out)\n",
        "    ff = self.ffn(x)\n",
        "    x = self.norm3(x + ff)\n",
        "    return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, num_tokens=5, d_model=2, max_len=3, n_blocks=1, num_heads=1): # num_tokens=5 untuk output_vocab\n",
        "    super().__init__()\n",
        "    self.we = nn.Embedding(num_embeddings=num_tokens, embedding_dim=d_model)\n",
        "    self.pe = PositionEncoding(d_model=d_model, max_len=max_len)\n",
        "    self.decoder_blocks = nn.ModuleList([\n",
        "            DecoderBlock(d_model=d_model, num_heads=num_heads, d_ff=8)\n",
        "            for block in range(n_blocks)\n",
        "        ])\n",
        "    self.fc_layer = nn.Linear(in_features=d_model, out_features=num_tokens)\n",
        "    self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  def forward(self, token_ids, encoder_out):\n",
        "    # token_ids shape: (batch_size, seq_len)\n",
        "    seq_len = token_ids.size(1) # Ambil panjang sekuens dari dimensi ke-1\n",
        "\n",
        "    word_embeddings = self.we(token_ids)\n",
        "    x = self.pe(word_embeddings)\n",
        "\n",
        "    # FIX: Buat mask berdasarkan seq_len, bukan batch_size\n",
        "    # Mask akan berbentuk (seq_len, seq_len)\n",
        "    mask = torch.tril(torch.ones(seq_len, seq_len)).to(self.device)\n",
        "    mask = mask == 0 # Invert mask agar nilai True diabaikan\n",
        "\n",
        "    for block in self.decoder_blocks:\n",
        "        x = block(x, encoder_out, mask)\n",
        "\n",
        "    fc_layer_output = self.fc_layer(x)\n",
        "    return fc_layer_output\n",
        "\n",
        "class Transformer(L.LightningModule):\n",
        "    def __init__(self, input_size, output_size, d_model=2, max_len=3):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(num_tokens=len(input_vocab), d_model=d_model, max_len=max_len)\n",
        "        self.decoder = Decoder(num_tokens=len(output_vocab), d_model=d_model, max_len=max_len)\n",
        "        self.loss = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "        self.output_vocab = output_vocab\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def forward(self, inputs, labels):\n",
        "        # PyTorch Lightning secara otomatis memindahkan tensor inputs dan labels\n",
        "        # ke device yang benar sebelum forward() dipanggil.\n",
        "        # Anda tidak perlu lagi menggunakan .to(self.device) di sini.\n",
        "        encoder_values = self.encoder(inputs)\n",
        "        output_presoftmax = self.decoder(labels, encoder_values)\n",
        "        return output_presoftmax\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return Adam(self.parameters(), lr=0.005)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        encoder_input, decoder_target = batch\n",
        "\n",
        "        if encoder_input.dim() == 1:\n",
        "            encoder_input = encoder_input.unsqueeze(0)\n",
        "            decoder_target = decoder_target.unsqueeze(0)\n",
        "\n",
        "        # Gunakan self.device yang sudah disediakan oleh PL\n",
        "        decoder_input = torch.cat([torch.tensor([[self.output_vocab['<SOS>']]]).to(self.device), decoder_target], dim=1)[:, :-1]\n",
        "\n",
        "        output = self.forward(encoder_input, decoder_input)\n",
        "\n",
        "        loss = self.loss(output.reshape(-1, output.size(-1)), decoder_target.reshape(-1))\n",
        "        self.log('train_loss', loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def predict(self, input_sentence_tensor, max_output_len=10):\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            if input_sentence_tensor.dim() == 1:\n",
        "                input_sentence_tensor = input_sentence_tensor.unsqueeze(0)\n",
        "\n",
        "            encoder_output = self.encoder(input_sentence_tensor.to(self.device))\n",
        "\n",
        "            decoder_input = torch.tensor([[self.output_vocab['<SOS>']]]).to(self.device)\n",
        "            predicted_tokens = []\n",
        "\n",
        "            for _ in range(max_output_len):\n",
        "                output_logits = self.decoder(decoder_input, encoder_output)\n",
        "                last_token_logits = output_logits[:, -1, :]\n",
        "                predicted_token_id = torch.argmax(last_token_logits, dim=-1)\n",
        "\n",
        "                if predicted_token_id.item() == self.output_vocab['<EOS>']:\n",
        "                    break\n",
        "\n",
        "                predicted_tokens.append(predicted_token_id.item())\n",
        "                decoder_input = torch.cat([decoder_input, predicted_token_id.unsqueeze(0)], dim=1)\n",
        "\n",
        "            id_to_word = {v: k for k, v in self.output_vocab.items()}\n",
        "            predicted_sentence = [id_to_word[token_id] for token_id in predicted_tokens]\n",
        "\n",
        "            return predicted_sentence\n",
        "\n",
        "# Inisialisasi dan pelatihan model\n",
        "transformer = Transformer(len(input_vocab), len(output_vocab), d_model=16, max_len=3)\n",
        "trainer = L.Trainer(max_epochs=50, enable_progress_bar=True)\n",
        "trainer.fit(transformer, train_dataloaders=dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694,
          "referenced_widgets": [
            "d31fbfa7470a4f26ac8d419d2979bead",
            "04c0fbc9c20f4fa8b7d958aad4f7103d",
            "84a1755a1b6b421aaaa1d0451df39241",
            "aa8ba5cbf5504a5c9cb1d12343dc5800",
            "e631567250f5412ea121ad4429cbc7cc",
            "c80c32c08ff34dfc971d59876992a6d1",
            "c4cb6a144aaf45ab8db48c8f40102728",
            "9075d1fab03f4a4b87ff430d6bc157dc",
            "a72dae748247471a9962b15ba90210bf",
            "ca627299fd4547f391053858e3edc55c",
            "c8e638b7b75d44af96c353453187930e"
          ]
        },
        "id": "VpWDxFswqjvU",
        "outputId": "4fe1ed4a-83d7-4e9e-dc63-19d62b3b64b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: 💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: \n",
            "  | Name    | Type             | Params | Mode \n",
            "-----------------------------------------------------\n",
            "0 | encoder | Encoder          | 1.4 K  | train\n",
            "1 | decoder | Decoder          | 2.7 K  | train\n",
            "2 | loss    | CrossEntropyLoss | 0      | train\n",
            "-----------------------------------------------------\n",
            "4.1 K     Trainable params\n",
            "0         Non-trainable params\n",
            "4.1 K     Total params\n",
            "0.016     Total estimated model params size (MB)\n",
            "46        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name    | Type             | Params | Mode \n",
            "-----------------------------------------------------\n",
            "0 | encoder | Encoder          | 1.4 K  | train\n",
            "1 | decoder | Decoder          | 2.7 K  | train\n",
            "2 | loss    | CrossEntropyLoss | 0      | train\n",
            "-----------------------------------------------------\n",
            "4.1 K     Trainable params\n",
            "0         Non-trainable params\n",
            "4.1 K     Total params\n",
            "0.016     Total estimated model params size (MB)\n",
            "46        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d31fbfa7470a4f26ac8d419d2979bead"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: `Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh penggunaan inferensi\n",
        "input_sentence = \"lets go\"\n",
        "input_tokens = [input_vocab[word] for word in input_sentence.split()]\n",
        "input_tensor = torch.tensor(input_tokens)\n",
        "\n",
        "print(f\"Menerjemahkan: '{input_sentence}' -> {input_tensor}\")\n",
        "predicted_translation = transformer.predict(input_tensor)\n",
        "print(f\"Hasil prediksi: {predicted_translation}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z42kj55vrCc6",
        "outputId": "9dd62996-fcb3-4e31-e5e1-eae65673e859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Menerjemahkan: 'lets go' -> tensor([1, 3])\n",
            "Hasil prediksi: ['vamos', 'y']\n"
          ]
        }
      ]
    }
  ]
}